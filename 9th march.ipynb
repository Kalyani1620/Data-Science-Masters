{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70b626f2-a794-4422-a85a-6b9bfa8dab1b",
   "metadata": {},
   "source": [
    "#### Q1: What are the Probability Mass Function (PMF) and Probability Density Function (PDF)? Explain with an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d29cbb-3f0b-44a4-a509-a418708c5ed9",
   "metadata": {},
   "source": [
    "Probability Mass Function (PMF) and Probability Density Function (PDF) are two mathematical functions that describe the probability distribution of a random variable.\n",
    "\n",
    "The PMF is a function that maps each possible outcome of a discrete random variable to its probability. In other words, it gives the probability of each possible value that a discrete random variable can take. The sum of all the probabilities in the PMF is always equal to 1. A simple example of a discrete random variable is the outcome of a coin toss. The PMF of a fair coin toss is:\n",
    "\n",
    "P(X=0) = 0.5 (when the coin lands on tails)\n",
    "P(X=1) = 0.5 (when the coin lands on heads)\n",
    "\n",
    "Here, X is the random variable that takes values 0 or 1, and P(X=x) is the probability that X takes the value x.\n",
    "\n",
    "On the other hand, the PDF is a function that describes the probability distribution of a continuous random variable. The PDF gives the probability of a random variable taking on any particular value within a range of values. The total area under the PDF curve is equal to 1. A simple example of a continuous random variable is the height of people in a population. The PDF of the height of people in a population can be modeled using a normal distribution curve. The PDF of a normal distribution is:\n",
    "\n",
    "f(x) = (1/σ√2π) e^−(x−μ)2/(2σ^2)\n",
    "\n",
    "Here, x is the value of the random variable, μ is the mean, σ is the standard deviation, and e is the base of the natural logarithm. The function f(x) gives the probability density of the random variable taking the value x. The probability of the random variable taking any value between a and b is given by the area under the curve of the PDF between a and b, which can be computed using integration.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeaac188-85c1-4c05-8ef1-bb3c194a933c",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb63a76-c3d7-4e4f-a26b-092e93809115",
   "metadata": {},
   "source": [
    "#### Q2: What is Cumulative Density Function (CDF)? Explain with an example. Why CDF is used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d92443-4410-40c7-ad76-27863b122dd6",
   "metadata": {},
   "source": [
    "The Cumulative Density Function (CDF) is a mathematical function that gives the probability that a random variable takes a value less than or equal to a certain value. In other words, the CDF gives the cumulative probability distribution of a random variable.\n",
    "\n",
    "The CDF is defined for both discrete and continuous random variables. For a discrete random variable, the CDF is defined as the sum of the probabilities of all the possible values less than or equal to the given value. For a continuous random variable, the CDF is defined as the integral of the PDF from minus infinity to the given value.\n",
    "\n",
    "Here's an example of a CDF for a discrete random variable. Consider a fair six-sided die. The CDF of the die is given by:\n",
    "\n",
    "F(x) = P(X ≤ x)\n",
    "\n",
    "where X is the random variable representing the value of the die roll. The CDF for this die can be expressed as:\n",
    "\n",
    "F(1) = 1/6\n",
    "F(2) = 2/6\n",
    "F(3) = 3/6\n",
    "F(4) = 4/6\n",
    "F(5) = 5/6\n",
    "F(6) = 1\n",
    "\n",
    "Here, F(x) gives the probability that the value of the die roll is less than or equal to x. For example, F(4) = 4/6, which means there is a 4/6 probability that the value of the die roll is less than or equal to 4.\n",
    "\n",
    "CDF is a useful concept in statistics and probability theory because it allows us to compute probabilities of ranges of values for random variables. For example, we can use the CDF to compute the probability that a continuous random variable takes a value between two given values by subtracting the CDF values at those two values. CDF is also used in hypothesis testing and confidence interval calculations.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f6d139-9afa-4c80-9a1a-223542ae6df1",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4598d813-1d79-40a6-9c82-ceb07d6af75a",
   "metadata": {},
   "source": [
    "#### Q3: What are some examples of situations where the normal distribution might be used as a model? Explain how the parameters of the normal distribution relate to the shape of the distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f3718d-7387-47af-b717-50d1e34f759f",
   "metadata": {},
   "source": [
    "The normal distribution, also known as the Gaussian distribution, is a common probability distribution that is used to model a wide range of phenomena in various fields. Here are some examples of situations where the normal distribution might be used as a model:\n",
    "\n",
    "Heights and weights of people: The normal distribution is often used to model the distribution of heights and weights of people in a population.\n",
    "\n",
    "Test scores: The normal distribution is commonly used to model the distribution of test scores in a large population.\n",
    "\n",
    "Measurement errors: The normal distribution is often used to model the distribution of measurement errors in scientific experiments.\n",
    "\n",
    "Stock prices: The normal distribution is sometimes used to model the distribution of stock prices.\n",
    "\n",
    "Natural phenomena: The normal distribution is used to model many natural phenomena, such as the distribution of rainfall or the temperature fluctuations in a region.\n",
    "\n",
    "The normal distribution is characterized by two parameters: the mean (μ) and the standard deviation (σ). The mean specifies the center of the distribution, and the standard deviation specifies the spread of the distribution.\n",
    "\n",
    "The shape of the normal distribution is symmetric and bell-shaped. The highest point of the bell curve corresponds to the mean of the distribution. The standard deviation determines the width of the bell curve. When the standard deviation is large, the curve is wider and flatter, indicating that the data is more spread out. When the standard deviation is small, the curve is narrower and taller, indicating that the data is more tightly clustered around the mean. The probability of a value occurring within a certain range of values can be calculated from the normal distribution using the mean and standard deviation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8fb510-a51a-4a28-8a1d-b5d0f9b1e271",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2bd944-f2e1-4182-b1b8-961caf7b460a",
   "metadata": {},
   "source": [
    "#### Q4: Explain the importance of Normal Distribution. Give a few real-life examples of Normal Distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f63d3a7-b64e-4657-9904-4ab0fd7700c5",
   "metadata": {},
   "source": [
    "The normal distribution, also known as the Gaussian distribution, is an important concept in statistics and probability theory. It has several applications in real life, and its importance lies in its ability to approximate many natural phenomena and simplify complex models.\n",
    "\n",
    "Here are some real-life examples of normal distribution:\n",
    "\n",
    "1. IQ scores: IQ scores are commonly distributed normally with a mean of 100 and a standard deviation of 15.\n",
    "\n",
    "2. Height and weight: The height and weight of individuals in a population are also distributed normally. The mean and standard deviation differ depending on factors such as age, gender, and ethnicity.\n",
    "\n",
    "3. Blood pressure: The systolic and diastolic blood pressures of individuals in a population are also normally distributed.\n",
    "\n",
    "4. Grades in a large class: The distribution of grades in a large class is often approximated by the normal distribution.\n",
    "\n",
    "5. Exam scores: The exam scores of a large group of students are often distributed normally.\n",
    "\n",
    "6. Errors in measurement: The errors in measurement in scientific experiments are often distributed normally.\n",
    "\n",
    "The normal distribution is important because it is a common approximation for many real-world phenomena, and it simplifies many complex models. It also allows us to make predictions and calculate probabilities for certain events. Additionally, many statistical techniques assume that the data is normally distributed, which means that understanding the normal distribution is important for statistical analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08e03da-9c09-4787-8a12-51cb3b7c587e",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42bb6cf0-dc63-496d-b19a-f9c2905b60fd",
   "metadata": {},
   "source": [
    "#### Q5: What is Bernaulli Distribution? Give an Example. What is the difference between Bernoulli Distribution and Binomial Distribution?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504c6ee9-383b-4151-92bb-334f2160ca07",
   "metadata": {},
   "source": [
    "The Bernoulli distribution is a discrete probability distribution that models the outcome of a single trial that can result in either success or failure. It is named after the Swiss mathematician Jacob Bernoulli, who studied it extensively in the early 18th century.\n",
    "\n",
    "The Bernoulli distribution has only one parameter, p, which represents the probability of success. The probability of failure is 1 - p. The probability mass function (PMF) of the Bernoulli distribution is:\n",
    "\n",
    "P(X=x) = p^x (1-p)^(1-x), for x=0 or 1\n",
    "\n",
    "where X is a random variable representing the outcome of the trial, and x can only take the values of 0 or 1, representing failure or success, respectively.\n",
    "\n",
    "An example of the Bernoulli distribution is the flipping of a coin, where the outcome can be either heads or tails. The probability of getting heads is p, and the probability of getting tails is 1-p.\n",
    "\n",
    "The difference between the Bernoulli distribution and the binomial distribution is that the Bernoulli distribution models the outcome of a single trial, while the binomial distribution models the outcome of a series of independent Bernoulli trials. The binomial distribution has two parameters, n and p, where n is the number of trials and p is the probability of success in each trial. The probability mass function (PMF) of the binomial distribution is:\n",
    "\n",
    "P(X=k) = (n choose k) * p^k * (1-p)^(n-k), for k = 0, 1, ..., n\n",
    "\n",
    "where X is a random variable representing the number of successes in n trials, and k is the number of successes. Therefore, the binomial distribution is the sum of n independent Bernoulli trials.\n",
    "\n",
    "For example, if we flip a coin 10 times, and the probability of getting heads is 0.5, then we can model this as a binomial distribution with n=10 and p=0.5. We can use the binomial distribution to calculate the probability of getting exactly 5 heads out of 10 flips."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fdeb469-8ca6-463f-97c0-864bf36e2ae9",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623962aa-7abb-4c67-87d5-7b00eb8a3f50",
   "metadata": {},
   "source": [
    "#### Q6. Consider a dataset with a mean of 50 and a standard deviation of 10. If we assume that the dataset is normally distributed, what is the probability that a randomly selected observation will be greater than 60? Use the appropriate formula and show your calculations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ba4dae-8452-4345-923b-941747796a0d",
   "metadata": {},
   "source": [
    "Given the dataset has a mean of 50 and a standard deviation of 10, we can assume that it follows a normal distribution with a mean of 50 and a standard deviation of 10.\n",
    "\n",
    "We are interested in finding the probability that a randomly selected observation will be greater than 60.\n",
    "\n",
    "We can use the standard normal distribution formula to calculate this probability:\n",
    "\n",
    "z = (x - mu) / sigma\n",
    "\n",
    "where z is the standard score, x is the value we are interested in, mu is the mean, and sigma is the standard deviation.\n",
    "\n",
    "Substituting the given values, we get:\n",
    "\n",
    "z = (60 - 50) / 10\n",
    "z = 1\n",
    "\n",
    "We can use a standard normal distribution table or calculator to find the probability that z is greater than 1.\n",
    "\n",
    "From the standard normal distribution table, we find that the probability of z being greater than 1 is approximately 0.1587.\n",
    "\n",
    "Therefore, the probability that a randomly selected observation from the dataset will be greater than 60 is approximately 0.1587 or 15.87%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f326c093-067a-454d-97b4-1a17a14fdb97",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506396de-0440-4395-9d0a-5037672e7c3f",
   "metadata": {},
   "source": [
    "#### Q7: Explain uniform Distribution with an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0d0b15-49fb-484d-8962-a0ac33a88df2",
   "metadata": {},
   "source": [
    "Uniform distribution is a probability distribution where each possible value of a random variable has an equal probability of occurring. This means that the probability density function is constant over a specified range.\n",
    "\n",
    "For example, let's consider a fair six-sided dice. When you roll the dice, each number has an equal probability of occurring, which is 1/6 or approximately 0.1667. Therefore, the probability of rolling a 1, 2, 3, 4, 5, or 6 on the dice is the same, and the distribution of the outcomes is uniform.\n",
    "\n",
    "The probability density function for a uniform distribution is defined as:\n",
    "\n",
    "f(x) = 1/(b-a)\n",
    "\n",
    "where a and b are the lower and upper bounds of the distribution, and x is a random variable between a and b. For the dice example, a = 1 and b = 6, so f(x) = 1/6 for all values of x between 1 and 6.\n",
    "\n",
    "Uniform distributions are used in many applications, such as in sampling methods, simulation studies, and random number generation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3feafcf9-23bb-485d-90ce-e14f33ea9943",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c15cd2-e461-48b4-a85b-9aaf76cc46d1",
   "metadata": {},
   "source": [
    "#### Q8: What is the z score? State the importance of the z score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d9e79d-c824-4652-853f-9ad966a70e1e",
   "metadata": {},
   "source": [
    "The z-score is a statistical measure that indicates how many standard deviations an observation is away from the mean of a dataset. It is also known as the standard score and is calculated by subtracting the mean of the dataset from the observed value and then dividing by the standard deviation.\n",
    "\n",
    "The formula for calculating the z-score is:\n",
    "\n",
    "z = (x - μ) / σ\n",
    "\n",
    "where x is the observed value, μ is the mean of the dataset, and σ is the standard deviation.\n",
    "\n",
    "The importance of the z-score lies in its ability to standardize data across different scales and distributions, making it easier to compare observations from different datasets. The z-score can be used to identify outliers, which are observations that fall outside of a certain range of values.\n",
    "\n",
    "Additionally, the z-score is used in hypothesis testing to determine the probability of obtaining a certain observation, assuming a certain null hypothesis. The z-score can also be used to calculate confidence intervals, which are estimates of the true population mean or proportion based on a sample of data.\n",
    "\n",
    "In summary, the z-score is an important statistical measure that provides a standardized way of comparing and analyzing data, and it has a wide range of applications in fields such as finance, economics, psychology, and medicine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ce7572-356b-4694-99cc-d339828c6c0c",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b1c561-241a-47d3-8b72-7888623bc7da",
   "metadata": {},
   "source": [
    "#### Q9: What is Central Limit Theorem? State the significance of the Central Limit Theorem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0767a203-d183-45f2-bb42-fe56af50f820",
   "metadata": {},
   "source": [
    "The Central Limit Theorem (CLT) is a fundamental theorem in statistics that describes the behavior of the means of a large number of independent and identically distributed random variables. The theorem states that regardless of the distribution of the individual random variables, the distribution of the sample means approaches a normal distribution as the sample size increases.\n",
    "\n",
    "The CLT can be stated mathematically as follows:\n",
    "\n",
    "Let X1, X2, ..., Xn be a random sample of size n drawn from a population with a finite mean μ and a finite variance σ^2. Then, as n approaches infinity, the distribution of the sample mean X̄ approaches a normal distribution with mean μ and standard deviation σ/√n, where X̄ is the sample mean.\n",
    "\n",
    "The significance of the Central Limit Theorem is that it allows us to make inferences about the population mean using the sample mean. In other words, it provides a framework for statistical inference and hypothesis testing that is widely used in many fields, including finance, economics, biology, and engineering.\n",
    "\n",
    "Additionally, the CLT helps to explain why the normal distribution arises so frequently in real-world applications. The theorem implies that the sum of a large number of random variables, regardless of their distribution, will tend to follow a normal distribution, which is a powerful and versatile tool for data analysis.\n",
    "\n",
    "Overall, the Central Limit Theorem is a fundamental concept in statistics that underpins many statistical methods and techniques. Its significance lies in its ability to provide a framework for statistical inference and hypothesis testing, and its widespread application across a variety of fields."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fc1067-39e8-4e81-8c0e-2ce1bcee9d97",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c8d111-8b8b-468d-84e5-e079aa0c3e52",
   "metadata": {},
   "source": [
    "#### Q10: State the assumptions of the Central Limit Theorem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aecaef55-70a3-42da-bbee-15e451811fa2",
   "metadata": {},
   "source": [
    "The Central Limit Theorem (CLT) is a fundamental theorem in statistics that describes the behavior of the means of a large number of independent and identically distributed random variables. However, the theorem has some assumptions that must be met for it to hold true. The assumptions of the Central Limit Theorem are:\n",
    "\n",
    "1. Independence: The random variables in the sample must be independent of each other. This means that the outcome of one variable does not affect the outcome of any other variable in the sample.\n",
    "\n",
    "2. Sample size: The sample size should be sufficiently large. While there is no strict rule for what constitutes a large enough sample size, a commonly used rule of thumb is that the sample size should be greater than or equal to 30.\n",
    "\n",
    "3. Finite mean and variance: The population from which the sample is drawn should have a finite mean (μ) and a finite variance (σ^2). This means that the distribution of the population should not be too skewed or have heavy tails.\n",
    "\n",
    "If these assumptions are met, the Central Limit Theorem states that the distribution of the sample means approaches a normal distribution as the sample size increases. However, it is important to note that violations of these assumptions may lead to inaccurate or misleading results. Therefore, it is important to verify these assumptions before applying the Central Limit Theorem in practice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e7d718-d443-47fe-8c20-b0f2c2713c81",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
